{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "podcast_download.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOudwjIl1izKRNkE0FMmblD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonAHeron/PodBlock/blob/main/podcast_download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ouYMo8IYlMH"
      },
      "source": [
        "pip install feedparser pydub google-cloud-speech recordtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaomqNOHZEM8"
      },
      "source": [
        "import feedparser\n",
        "import os\n",
        "from recordtype import recordtype\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "from pydub import AudioSegment\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from google.cloud import speech\n",
        "import random\n",
        "from difflib import SequenceMatcher\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp7gcLaUqMf5"
      },
      "source": [
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.environ['GCP_PROJECT'] = 'podblock'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/My Drive/podblock/gc-creds.json'\n",
        "speech_client = speech.SpeechClient()\n",
        "gcs_service = build('storage', 'v1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg9LaNwiZKjF"
      },
      "source": [
        "second = 1000\n",
        "minute = 60 * second\n",
        "daily_rss_url = \"https://feeds.simplecast.com/54nAGcIl\"\n",
        "daily_rss_feed = feedparser.parse(daily_rss_url)\n",
        "daily_rss_entries = daily_rss_feed.entries\n",
        "Episode = recordtype('Episode', 'title url file audio_segment')\n",
        "episodes = []\n",
        "for entry in daily_rss_entries:\n",
        "  episodes.append(Episode(entry['title'], entry['links'][1]['href'], '', ''))\n",
        "print(f\"Ready to process {len(episodes)} episodes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TdsYs5todA2"
      },
      "source": [
        "podblock_audio_directory = \"/content/drive/My Drive/podblock/audio\"\n",
        "training_file_directory = f\"{podblock_audio_directory}/train\"\n",
        "training_content_directory = f\"{training_file_directory}/content\"\n",
        "training_ad_directory = f\"{training_file_directory}/ad\"\n",
        "test_file_directory = f\"{podblock_audio_directory}/test\"\n",
        "test_content_directory = f\"{test_file_directory}/content\"\n",
        "test_ad_directory = f\"{test_file_directory}/ad\"\n",
        "ad_text_directory = \"/content/drive/My Drive/podblock/ad_text_for_deduping\"\n",
        "\n",
        "\n",
        "def makeDir(dir):\n",
        "  try:\n",
        "    os.mkdir(dir)\n",
        "  except FileExistsError:\n",
        "      print(\"Folder already found\")\n",
        "\n",
        "makeDir(podblock_audio_directory)\n",
        "makeDir(training_file_directory)\n",
        "makeDir(test_file_directory)\n",
        "makeDir(training_content_directory)\n",
        "makeDir(test_content_directory)\n",
        "makeDir(test_ad_directory)\n",
        "makeDir(ad_text_directory)\n",
        "makeDir(training_ad_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D94pmVNQJ55W"
      },
      "source": [
        "def uploadAudioSegmentToGcs(episode, start, end):\n",
        "  print(f\"Uploading flac encoded audio to GCS for: {episode.title}\")\n",
        "  flac_dir = f\"{episode.file[:-3]}flac\"\n",
        "  upload_filename = flac_dir.split('/')[-1]\n",
        "  episode.audio_segment[start:end].export(flac_dir, format = \"flac\")\n",
        "  media = MediaFileUpload(flac_dir, resumable=True)\n",
        "  request = gcs_service.objects().insert(bucket='podblock_audio_full', \n",
        "                                         name=upload_filename,\n",
        "                                         media_body=media)\n",
        "  response = None\n",
        "  while response is None:\n",
        "    progress, response = request.next_chunk()\n",
        "  return f\"gs://podblock_audio_full/{upload_filename}\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n81OXFKUQW1"
      },
      "source": [
        "def longRecognizeSTT(gcs_uri):\n",
        "  audio = speech.RecognitionAudio(uri=gcs_uri)\n",
        "  config = speech.RecognitionConfig(\n",
        "      encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
        "      audio_channel_count=1,\n",
        "      #enable_word_time_offsets=True,\n",
        "      #enable_automatic_punctuation=True,\n",
        "      model=\"video\",\n",
        "      use_enhanced=True,\n",
        "      language_code=\"en-US\",\n",
        "  )\n",
        "  # Detects speech in the audio file\n",
        "  operation = speech_client.long_running_recognize(config=config, audio=audio)\n",
        "  print(f\"Recognizing speech in : {gcs_uri}\")\n",
        "  response = operation.result()\n",
        "  print(\"Speech recognition completed\")\n",
        "  return response\n",
        "\n",
        "def shortRecognizeSTT(file):\n",
        "  print(f\"Short recognize for: {file}\")\n",
        "  with open(file, \"rb\") as audio_file:\n",
        "    content = audio_file.read()\n",
        "    audio = speech.RecognitionAudio(content=content)\n",
        "    config = speech.RecognitionConfig(\n",
        "      encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
        "      audio_channel_count=1,\n",
        "      model=\"video\",\n",
        "      use_enhanced=True,\n",
        "      language_code=\"en-US\",\n",
        "    )\n",
        "    operation = speech_client.long_running_recognize(config=config, audio=audio)\n",
        "    response = operation.result(timeout=90)\n",
        "    output = ''\n",
        "    for result in response.results:\n",
        "      output += result.alternatives[0].transcript\n",
        "    return output"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfICz658XzKq"
      },
      "source": [
        "def uploadRecognizedTextToDrive(title, stt_response):\n",
        "  with open(f\"/content/drive/My Drive/podblock/podcast_text/{title}.txt\", 'w') as f:\n",
        "    for result in stt_response.results:\n",
        "      f.write(\"Result: {}\\n\".format(result))\n",
        "\n",
        "def uploadAdDedupeTextToDrive(text, filename):\n",
        "  with open(f\"{ad_text_directory}/{filename}.txt\", 'w') as f:\n",
        "    f.write(text)\n",
        "\n",
        "def loadAdDedupTextFromDrive():\n",
        "  known_ad_text = set()\n",
        "  for root, dirs, files in os.walk(ad_text_directory):\n",
        "    for file in files:\n",
        "      with open(os.path.join(root, file), 'r') as ad_text:\n",
        "        known_ad_text.add(ad_text.read())\n",
        "  return known_ad_text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzlaVPcZOAOD"
      },
      "source": [
        "def audioAlreadyProcessed(episode):\n",
        "  return os.path.exists(f\"{training_content_directory}/{episode.title}.wav\") or os.path.exists(f\"{test_content_directory}/{episode.title}.wav\")\n",
        "\n",
        "def randomUpload(audio_segment, title, isAd=True):\n",
        "  coin_flip = random.randint(0, 1)\n",
        "  if(isAd):\n",
        "    upload_location = training_ad_directory if coin_flip else test_ad_directory\n",
        "    audio_segment.export(f\"{upload_location}/{title}.wav\", format=\"wav\", bitrate='16k')\n",
        "  else:\n",
        "    upload_location = training_content_directory if coin_flip else test_content_directory\n",
        "    audio_segment.export(f\"{upload_location}/{title}.wav\", format=\"wav\", bitrate='16k')\n",
        "\n",
        "def isKnownAd(ad_text, known_ad_text):\n",
        "  for known_ad in known_ad_text:\n",
        "    ratio = SequenceMatcher(None, ad_text, known_ad).ratio()\n",
        "    if ratio > .6:\n",
        "      print(f\"Found known ad\\n{known_ad}\\n{ad_text}\\nRATIO: {ratio}\")\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def encodeAndUploadAudioSegments(episode, known_ad_text):\n",
        "  print(f\"Uploading wav encoded audio segments to drive\")\n",
        "  preroll_ad = episode.audio_segment[:30 * second]\n",
        "  preroll_file = f\"{episode.file[:-4]}-preroll.flac\"\n",
        "  preroll_ad.export(preroll_file, format = \"flac\")\n",
        "  preroll_text = shortRecognizeSTT(preroll_file)\n",
        "\n",
        "  # postroll_ad = episode.audio_segment[-30 * second:]\n",
        "  # postroll_file = f\"{episode.file[:-4]}-postroll.flac\"\n",
        "  # postroll_ad.export(postroll_file, format = \"flac\")\n",
        "  # postroll_text = shortRecognizeSTT(postroll_file)\n",
        "\n",
        "  if(not isKnownAd(preroll_text, known_ad_text)):\n",
        "    print(f\"Found new unknown ad: {preroll_text}\")\n",
        "    randomUpload(preroll_ad, episode.title)\n",
        "    uploadAdDedupeTextToDrive(preroll_text, f\"{episode.title}-preroll\")\n",
        "    known_ad_text.add(preroll_text)\n",
        "\n",
        "  # if(not isKnownAd(postroll_text, known_ad_text)):\n",
        "  #   randomUpload(postroll_ad, episode.title)\n",
        "  #   uploadAdDedupeTextToDrive(postroll_text, f\"{episode.title}-postroll\")\n",
        "  #   known_ad_text.add(postroll_text)\n",
        "\n",
        "  content = episode.audio_segment[31 * second:5 * minute]\n",
        "  randomUpload(content, episode.title, False)\n",
        "\n",
        "  os.remove(preroll_file)\n",
        "  #os.remove(postroll_file)\n",
        "\n",
        "  return known_ad_text"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZu3kVvz1x5m"
      },
      "source": [
        "def uploadTextContent(content_gcs_uri):\n",
        "  #response = longRecognizeSTT(content_gcs_uri)\n",
        "  #uploadRecognizedTextToDrive(selected_episode.title, stt_response)\n",
        "  pass"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx4Ob7MyjJdL"
      },
      "source": [
        "known_ad_texts = loadAdDedupTextFromDrive()\n",
        "print(f\"Loaded {len(known_ad_texts)} known ads\")\n",
        "for episode in tqdm(episodes):\n",
        "  if(episode.title.startswith(\"The Sunday Read:\")):\n",
        "    continue\n",
        "  ## Audio Pipeline\n",
        "  if(audioAlreadyProcessed(episode)):\n",
        "    print(f\"Already processed audio for: {episode.title}\")\n",
        "  else:\n",
        "    print(f\"\\nProcessing audio pipeline for: {episode.title}\")\n",
        "    episode.file = tf.keras.utils.get_file(f'{episode.title}.mp3', episode.url, cache_dir='./', cache_subdir='data')\n",
        "    episode.audio_segment = AudioSegment.from_mp3(episode.file).set_channels(1)\n",
        "    known_ad_texts = encodeAndUploadAudioSegments(episode, known_ad_texts)\n",
        "  ## Semantic Pipeline\n",
        "  #content_gcs_uri = uploadAudioSegmentToGcs(episode, 31 * second, 5 * minute)\n",
        "  #uploadTextContent(content_gcs_uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKNwT6Dzqxjp"
      },
      "source": [
        "drive.flush_and_unmount()\n"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}